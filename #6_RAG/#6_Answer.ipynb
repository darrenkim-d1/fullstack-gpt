{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a31814",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 717, which is longer than the specified 600\n",
      "Created a chunk of size 608, which is longer than the specified 600\n",
      "Created a chunk of size 642, which is longer than the specified 600\n",
      "Created a chunk of size 1444, which is longer than the specified 600\n",
      "Created a chunk of size 1251, which is longer than the specified 600\n",
      "Created a chunk of size 1012, which is longer than the specified 600\n",
      "Created a chunk of size 1493, which is longer than the specified 600\n",
      "Created a chunk of size 819, which is longer than the specified 600\n",
      "Created a chunk of size 1458, which is longer than the specified 600\n",
      "Created a chunk of size 1411, which is longer than the specified 600\n",
      "Created a chunk of size 742, which is longer than the specified 600\n",
      "Created a chunk of size 669, which is longer than the specified 600\n",
      "Created a chunk of size 906, which is longer than the specified 600\n",
      "Created a chunk of size 703, which is longer than the specified 600\n",
      "Created a chunk of size 1137, which is longer than the specified 600\n",
      "Created a chunk of size 1417, which is longer than the specified 600\n",
      "Created a chunk of size 1200, which is longer than the specified 600\n",
      "Created a chunk of size 859, which is longer than the specified 600\n",
      "Created a chunk of size 845, which is longer than the specified 600\n",
      "Created a chunk of size 716, which is longer than the specified 600\n",
      "Created a chunk of size 840, which is longer than the specified 600\n",
      "Created a chunk of size 1042, which is longer than the specified 600\n",
      "Created a chunk of size 652, which is longer than the specified 600\n",
      "Created a chunk of size 985, which is longer than the specified 600\n",
      "Created a chunk of size 859, which is longer than the specified 600\n",
      "Created a chunk of size 659, which is longer than the specified 600\n",
      "Created a chunk of size 693, which is longer than the specified 600\n",
      "Created a chunk of size 817, which is longer than the specified 600\n",
      "Created a chunk of size 655, which is longer than the specified 600\n",
      "Created a chunk of size 1345, which is longer than the specified 600\n",
      "Created a chunk of size 1339, which is longer than the specified 600\n",
      "Created a chunk of size 1288, which is longer than the specified 600\n",
      "Created a chunk of size 1014, which is longer than the specified 600\n",
      "Created a chunk of size 617, which is longer than the specified 600\n",
      "Created a chunk of size 617, which is longer than the specified 600\n",
      "Created a chunk of size 1178, which is longer than the specified 600\n",
      "Created a chunk of size 1444, which is longer than the specified 600\n",
      "Created a chunk of size 802, which is longer than the specified 600\n",
      "Created a chunk of size 1496, which is longer than the specified 600\n",
      "Created a chunk of size 841, which is longer than the specified 600\n",
      "Created a chunk of size 743, which is longer than the specified 600\n",
      "Created a chunk of size 694, which is longer than the specified 600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "질문: Aaronson 은 유죄인가요?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "He accepted everything. The past was alterable. The past never had been altered. Oceania was at war with Eastasia. Oceania had always been at war with Eastasia. Jones, Aaronson, and Rutherford were guilty of the crimes they were charged with. He had never seen the photograph that disproved their guilt. It had never existed, he had invented it. He remembered remembering contrary things, but those were false memories, products of self-deception. How easy it all was! Only surrender, and everything else followed. It was like swimming against a current that swept you backwards however hard you struggled, and then suddenly deciding to turn round and go with the current instead of opposing it. Nothing had changed except your own attitude: the predestined thing happened in any case. He hardly knew why he had ever rebelled. Everything was easy, except----!\n",
      "\n",
      "He accepted everything. The past was alterable. The past never had been altered. Oceania was at war with Eastasia. Oceania had always been at war with Eastasia. Jones, Aaronson, and Rutherford were guilty of the crimes they were charged with. He had never seen the photograph that disproved their guilt. It had never existed, he had invented it. He remembered remembering contrary things, but those were false memories, products of self-deception. How easy it all was! Only surrender, and everything else followed. It was like swimming against a current that swept you backwards however hard you struggled, and then suddenly deciding to turn round and go with the current instead of opposing it. Nothing had changed except your own attitude: the predestined thing happened in any case. He hardly knew why he had ever rebelled. Everything was easy, except----!\n",
      "\n",
      "He accepted everything. The past was alterable. The past never had been altered. Oceania was at war with Eastasia. Oceania had always been at war with Eastasia. Jones, Aaronson, and Rutherford were guilty of the crimes they were charged with. He had never seen the photograph that disproved their guilt. It had never existed, he had invented it. He remembered remembering contrary things, but those were false memories, products of self-deception. How easy it all was! Only surrender, and everything else followed. It was like swimming against a current that swept you backwards however hard you struggled, and then suddenly deciding to turn round and go with the current instead of opposing it. Nothing had changed except your own attitude: the predestined thing happened in any case. He hardly knew why he had ever rebelled. Everything was easy, except----!\n",
      "\n",
      "He accepted everything. The past was alterable. The past never had been altered. Oceania was at war with Eastasia. Oceania had always been at war with Eastasia. Jones, Aaronson, and Rutherford were guilty of the crimes they were charged with. He had never seen the photograph that disproved their guilt. It had never existed, he had invented it. He remembered remembering contrary things, but those were false memories, products of self-deception. How easy it all was! Only surrender, and everything else followed. It was like swimming against a current that swept you backwards however hard you struggled, and then suddenly deciding to turn round and go with the current instead of opposing it. Nothing had changed except your own attitude: the predestined thing happened in any case. He hardly knew why he had ever rebelled. Everything was easy, except----!\n",
      "Human: Aaronson 은 유죄인가요?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "답변: 네, Jones, Aaronson, 그리고 Rutherford는 그들이 기소된 범죄로 유죄로 판결받았습니다.\n",
      "\n",
      "질문: 그가 테이블에 어떤 메시지를 썼나요?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: Aaronson 은 유죄인가요?\n",
      "Assistant: 네, Jones, Aaronson, 그리고 Rutherford는 그들이 기소된 범죄로 유죄로 판결받았습니다.\n",
      "Follow Up Input: 그가 테이블에 어떤 메시지를 썼나요?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "He lay back on the bed and tried to compose himself. What had he done? How many years had he added to his servitude by that moment of weakness?\n",
      "\n",
      "He lay back on the bed and tried to compose himself. What had he done? How many years had he added to his servitude by that moment of weakness?\n",
      "\n",
      "He lay back on the bed and tried to compose himself. What had he done? How many years had he added to his servitude by that moment of weakness?\n",
      "\n",
      "He lay back on the bed and tried to compose himself. What had he done? How many years had he added to his servitude by that moment of weakness?\n",
      "Human: 그가 테이블에 어떤 메시지를 썼습니까?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "답변: 죄송합니다, 제가 그 질문에 대한 정보를 알 수 없습니다.\n",
      "\n",
      "질문: Julia 는 누구인가요?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: Aaronson 은 유죄인가요?\n",
      "Assistant: 네, Jones, Aaronson, 그리고 Rutherford는 그들이 기소된 범죄로 유죄로 판결받았습니다.\n",
      "Human: 그가 테이블에 어떤 메시지를 썼나요?\n",
      "Assistant: 죄송합니다, 제가 그 질문에 대한 정보를 알 수 없습니다.\n",
      "Follow Up Input: Julia 는 누구인가요?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "'Do it to Julia! Do it to Julia! Not me! Julia! I don't care what you do to her. Tear her face off, strip her to the bones. Not me! Julia! Not me!'\n",
      "\n",
      "'Do it to Julia! Do it to Julia! Not me! Julia! I don't care what you do to her. Tear her face off, strip her to the bones. Not me! Julia! Not me!'\n",
      "\n",
      "'Do it to Julia! Do it to Julia! Not me! Julia! I don't care what you do to her. Tear her face off, strip her to the bones. Not me! Julia! Not me!'\n",
      "\n",
      "'Do it to Julia! Do it to Julia! Not me! Julia! I don't care what you do to her. Tear her face off, strip her to the bones. Not me! Julia! Not me!'\n",
      "Human: Julia는 누구인가요?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "답변: Julia는 조지 오웰의 소설 '1984'에서 주인공 윈스턴 스미스가 사랑하는 여성 캐릭터입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import Chroma, FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "cache_dir = LocalFileStore(\"../.cache/\")\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    # max_token_limit=120,\n",
    "    return_messages=True,\n",
    "    memory_key=\"chat_history\",\n",
    "    output_key=\"answer\"\n",
    ")\n",
    "\n",
    "splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "loader = UnstructuredFileLoader(\"../files/chapter_03.txt\")\n",
    "\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)\n",
    "\n",
    "vectorstore = Chroma.from_documents(docs, cached_embeddings)\n",
    "# vectorstore = FAISS.from_documents(docs, cached_embeddings)\n",
    "\n",
    "# chain = RetrievalQA.from_chain_type(\n",
    "#     llm=llm,\n",
    "#     chain_type=\"stuff\",\n",
    "#     retriever=vectorstore.as_retriever()\n",
    "# )\n",
    "\n",
    "chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    memory=memory,\n",
    "    chain_type=\"stuff\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# chain.run(\"Aaronson 은 유죄인가요?\")\n",
    "# chain.run(\"그가 테이블에 어떤 메시지를 썼나요?\")\n",
    "# chain.run(\"Julia 는 누구인가요?\")\n",
    "\n",
    "questions = [\n",
    "    \"Aaronson 은 유죄인가요?\",\n",
    "    \"그가 테이블에 어떤 메시지를 썼나요?\",\n",
    "    \"Julia 는 누구인가요?\"\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\n질문: {question}\")\n",
    "    response = chain({\"question\": question})\n",
    "    print(f\"답변: {response['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b268265e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
