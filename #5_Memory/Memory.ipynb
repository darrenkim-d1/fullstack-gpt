{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "807265f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Hi!\\nAI: ì˜¤ëŠ˜ í•˜ë£¨ ì–´ë•Œ?'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=False)\n",
    "\n",
    "memory.save_context({\"input\":\"Hi!\"}, {\"output\":\"ì˜¤ëŠ˜ í•˜ë£¨ ì–´ë•Œ?\"})\n",
    "\n",
    "memory.load_memory_variables({})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6747bc7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='2'),\n",
       "  AIMessage(content='2'),\n",
       "  HumanMessage(content='3'),\n",
       "  AIMessage(content='3'),\n",
       "  HumanMessage(content='4'),\n",
       "  AIMessage(content='4')]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(return_messages=True, k=3)\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\":input}, {\"output\":output})\n",
    "\n",
    "add_message(1, 1)\n",
    "add_message(2, 2)\n",
    "add_message(3, 3)\n",
    "add_message(4, 4)\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a81a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"The human introduces themselves as ê¹€ì§„ë²” from ì˜ì •ë¶€, South Korea, and the AI responds with a friendly greeting, saying it's nice to meet them.\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm)\n",
    "\n",
    "def get_history():\n",
    "    return memory.load_memory_variables({})\n",
    "\n",
    "add_message(\"ì•ˆë…• ë‚˜ëŠ” ê¹€ì§„ë²”ì´ë¼ê³  í•´, í•œêµ­ ì˜ì •ë¶€ë¼ëŠ” ë„ì‹œì— ì‚´ê³  ìˆì–´\", \"ì•ˆë…• ë§Œë‚˜ì„œ ë°˜ê°€ì›Œ\")\n",
    "add_message(\"ì•ˆë…• ë‚˜ëŠ” ê¹€ì§„ë²”ì´ë¼ê³  í•´, í•œêµ­ ì˜ì •ë¶€ë¼ëŠ” ë„ì‹œì— ì‚´ê³  ìˆì–´2\", \"ì•ˆë…• ë§Œë‚˜ì„œ ë°˜ê°€ì›Œ2\")\n",
    "\n",
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e773725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content=\"The human introduces themselves as Kim Jinbeom from the city of Uijeongbu in South Korea. The AI responds in Korean, saying it's nice to meet Kim Jinbeom. Kim Jinbeom responds in Korean, saying hello and mentioning that they live in Uijeongbu, South Korea.\"),\n",
       "  AIMessage(content='ì•ˆë…• ë§Œë‚˜ì„œ ë°˜ê°€ì›Œ')]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=50,\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "add_message(\"ì•ˆë…• ë‚˜ëŠ” ê¹€ì§„ë²”ì´ë¼ê³  í•´, í•œêµ­ ì˜ì •ë¶€ë¼ëŠ” ë„ì‹œì— ì‚´ê³  ìˆì–´\", \"ì•ˆë…• ë§Œë‚˜ì„œ ë°˜ê°€ì›Œ\")\n",
    "add_message(\"ì•ˆë…• ë‚˜ëŠ” ê¹€ì§„ë²”ì´ë¼ê³  í•´, í•œêµ­ ì˜ì •ë¶€ë¼ëŠ” ë„ì‹œì— ì‚´ê³  ìˆì–´\", \"ì•ˆë…• ë§Œë‚˜ì„œ ë°˜ê°€ì›Œ\")\n",
    "\n",
    "get_history()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "127d9173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: ë„ˆëŠ” ë„ì›€ì„ ì£¼ëŠ” ì‹œìŠ¤í…œì´ì•¼\n",
      "Human: ë‚´ ì´ë¦„ì€ jinbeomì´ì•¼\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ì•ˆë…• jinbeom! ë§Œë‚˜ì„œ ë°˜ê°€ì›Œ. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œ?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ë„ˆëŠ” ë„ì›€ì„ ì£¼ëŠ” ì‹œìŠ¤í…œì´ì•¼\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=prompt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.predict(question=\"ë‚´ ì´ë¦„ì€ jinbeomì´ì•¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8d4f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='ğŸ˜±ğŸ”«ğŸ•µï¸\\u200dâ™‚ï¸'\n",
      "content='ë¯¸ì•ˆí•´ìš”, ë°©ê¸ˆ ë§í•œ ì˜í™” ì œëª©ì€ \"ì‹ ì„¸ê³„\"ì—ìš”.'\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"íƒ‘ê±´\",\n",
    "        \"answer\": \"\"\"\n",
    "            ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\n",
    "        \"\"\"\n",
    "    }, \n",
    "    {\n",
    "        \"question\": \"ëŒ€ë¶€\",\n",
    "        \"answer\": \"\"\"\n",
    "            ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ\n",
    "        \"\"\"\n",
    "    }    \n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{movie}\"),\n",
    "        (\"ai\", \"{answer}\"),\n",
    "    ]\n",
    ")\n",
    "example_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ë„ˆëŠ” ì˜í™” ì œëª©ì„ ë“£ê³  ì„¸ê°œì˜ ì´ëª¨í‹°ì½˜ìœ¼ë¡œ í‘œí˜„í•´ì•¼í•´\"),\n",
    "        # (\"system\", \"ë„ˆëŠ” ëŒ€í™”ë¥¼ ë„ì™€ì¤˜ì•¼ í•´\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{movie}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "def load_memory(_):\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "chain = RunnablePassthrough.assign(history=load_memory) | prompt | llm\n",
    "\n",
    "def invoke_chain(question):\n",
    "    result = chain.invoke({\"movie\": question})\n",
    "    memory.save_context(\n",
    "        {\"input\":question},\n",
    "        {\"output\": result.content}\n",
    "    )\n",
    "    print(result)\n",
    "\n",
    "invoke_chain(\"ì‹ ì„¸ê³„\")\n",
    "invoke_chain(\"ì•ì—ì„œ ë§í•œ ì˜í™”ì œëª©ì€ ë­ì§€?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
