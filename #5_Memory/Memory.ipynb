{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807265f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=False)\n",
    "\n",
    "memory.save_context({\"input\":\"Hi!\"}, {\"output\":\"ì˜¤ëŠ˜ í•˜ë£¨ ì–´ë•Œ?\"})\n",
    "\n",
    "memory.load_memory_variables({})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6747bc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(return_messages=True, k=3)\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"input\":input}, {\"output\":output})\n",
    "\n",
    "add_message(1, 1)\n",
    "add_message(2, 2)\n",
    "add_message(3, 3)\n",
    "add_message(4, 4)\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a81a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm)\n",
    "\n",
    "def get_history():\n",
    "    return memory.load_memory_variables({})\n",
    "\n",
    "add_message(\"ì•ˆë…• ë‚˜ëŠ” ê¹€ì§„ë²”ì´ë¼ê³  í•´, í•œêµ­ ì˜ì •ë¶€ë¼ëŠ” ë„ì‹œì— ì‚´ê³  ìˆì–´\", \"ì•ˆë…• ë§Œë‚˜ì„œ ë°˜ê°€ì›Œ\")\n",
    "add_message(\"ì•ˆë…• ë‚˜ëŠ” ê¹€ì§„ë²”ì´ë¼ê³  í•´, í•œêµ­ ì˜ì •ë¶€ë¼ëŠ” ë„ì‹œì— ì‚´ê³  ìˆì–´2\", \"ì•ˆë…• ë§Œë‚˜ì„œ ë°˜ê°€ì›Œ2\")\n",
    "\n",
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e773725",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=50,\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "add_message(\"ì•ˆë…• ë‚˜ëŠ” ê¹€ì§„ë²”ì´ë¼ê³  í•´, í•œêµ­ ì˜ì •ë¶€ë¼ëŠ” ë„ì‹œì— ì‚´ê³  ìˆì–´\", \"ì•ˆë…• ë§Œë‚˜ì„œ ë°˜ê°€ì›Œ\")\n",
    "add_message(\"ì•ˆë…• ë‚˜ëŠ” ê¹€ì§„ë²”ì´ë¼ê³  í•´, í•œêµ­ ì˜ì •ë¶€ë¼ëŠ” ë„ì‹œì— ì‚´ê³  ìˆì–´\", \"ì•ˆë…• ë§Œë‚˜ì„œ ë°˜ê°€ì›Œ\")\n",
    "\n",
    "get_history()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127d9173",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ë„ˆëŠ” ë„ì›€ì„ ì£¼ëŠ” ì‹œìŠ¤í…œì´ì•¼\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=prompt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "chain.predict(question=\"ë‚´ ì´ë¦„ì€ jinbeomì´ì•¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8d4f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"íƒ‘ê±´\",\n",
    "        \"answer\": \"\"\"\n",
    "            ğŸ›©ï¸ğŸ‘¨â€âœˆï¸ğŸ”¥\n",
    "        \"\"\"\n",
    "    }, \n",
    "    {\n",
    "        \"question\": \"ëŒ€ë¶€\",\n",
    "        \"answer\": \"\"\"\n",
    "            ğŸ‘¨â€ğŸ‘¨â€ğŸ‘¦ğŸ”«ğŸ\n",
    "        \"\"\"\n",
    "    }    \n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{movie}\"),\n",
    "        (\"ai\", \"{answer}\"),\n",
    "    ]\n",
    ")\n",
    "example_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ë„ˆëŠ” ì˜í™” ì œëª©ì„ ë“£ê³  ì„¸ê°œì˜ ì´ëª¨í‹°ì½˜ìœ¼ë¡œ í‘œí˜„í•´ì•¼í•´\"),\n",
    "        # (\"system\", \"ë„ˆëŠ” ëŒ€í™”ë¥¼ ë„ì™€ì¤˜ì•¼ í•´\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{movie}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "def load_memory(_):\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "chain = RunnablePassthrough.assign(history=load_memory) | prompt | llm\n",
    "\n",
    "def invoke_chain(question):\n",
    "    result = chain.invoke({\"movie\": question})\n",
    "    memory.save_context(\n",
    "        {\"input\":question},\n",
    "        {\"output\": result.content}\n",
    "    )\n",
    "    print(result)\n",
    "\n",
    "invoke_chain(\"ì‹ ì„¸ê³„\")\n",
    "invoke_chain(\"ì•ì—ì„œ ë§í•œ ì˜í™”ì œëª©ì€ ë­ì§€?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
